{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with Discrete Latent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "from pyro import poutine\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "from pyro.ops.indexing import Vindex\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation()\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mechanics of enumeration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传统的来进行discrete Variables采样的方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guide z = 3\n",
      "model z = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model():\n",
    "    z = pyro.sample(\"z\", dist.Categorical(torch.ones(5)))\n",
    "    print(\"model z = {}\".format(z))\n",
    "    \n",
    "def guide():\n",
    "    z = pyro.sample(\"z\", dist.Categorical(torch.ones(5)))\n",
    "    print(\"guide z = {}\".format(z))\n",
    "    \n",
    "elbo = Trace_ELBO()\n",
    "elbo.loss(model, guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们使用enumeration的时候，pyro会把应用于discrete variables的`sample`解释为enumerate，就会有以下的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guide z = tensor([0, 1, 2, 3, 4])\n",
      "model z = tensor([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elbo = TraceEnum_ELBO(max_plate_nesting=0)\n",
    "elbo.loss(model, config_enumerate(guide, \"parallel\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到我们的样本的维度发生了变化，这来自于distribution的`enumerate_support()`方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，我们使用的enumerate方式是`parallel`，这在效率上是高效的，但因为改变了sample的维度，所以在后续code中必须加上一些特定的步骤来防止出现错误的结果。\n",
    "\n",
    "另外我们还可以选择的enumerate方式是`sequential`，其每次采样的结果和非enumerate时是一样的，但会采样多次，直到所有的discrete variables pairs都遍历完。这使得我们能够更加灵活的去实现模型，但也增加了运行成本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guide z = 4\n",
      "model z = 4\n",
      "guide z = 3\n",
      "model z = 3\n",
      "guide z = 2\n",
      "model z = 2\n",
      "guide z = 1\n",
      "model z = 1\n",
      "guide z = 0\n",
      "model z = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elbo = TraceEnum_ELBO(max_plate_nesting=0)\n",
    "elbo.loss(model, config_enumerate(guide, \"sequential\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Latent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果有多个discrete variables？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model x.shape = torch.Size([3])\n",
      "model y.shape = torch.Size([3, 1])\n",
      "model z.shape = torch.Size([3, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@config_enumerate\n",
    "def model():\n",
    "    p = pyro.param(\"p\", torch.randn(3, 3).exp(), constraint=constraints.simplex)\n",
    "    x = pyro.sample(\"x\", dist.Categorical(p[0]))\n",
    "    y = pyro.sample(\"y\", dist.Categorical(p[x]))\n",
    "    z = pyro.sample(\"z\", dist.Categorical(p[y]))\n",
    "    print(\"model x.shape = {}\".format(x.shape))\n",
    "    print(\"model y.shape = {}\".format(y.shape))\n",
    "    print(\"model z.shape = {}\".format(z.shape))\n",
    "    return x, y, z\n",
    "    \n",
    "def guide():\n",
    "    pass\n",
    "\n",
    "pyro.clear_param_store()\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=0)\n",
    "elbo.loss(model, guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，这在“TensorShape”中我们介绍过了：enumeration mode会分配每个discrete variables一个dimension来储存其enumeration，但为了节约空间，这些dimensions除了最左边的那一个，其他都是1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model x.shape = torch.Size([])\n",
      "model y.shape = torch.Size([])\n",
      "model z.shape = torch.Size([])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(2), tensor(0), tensor(0))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examing discrete latent states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，如果使用了enumeration，我们得到的内容就是包括了enumeration dimensions的tensor了。为了能够得到这些discrete latent variables的采样值，我们可以使用`infer_discrete`来wrap一下model，其中需要参数`first_avarible_dim=-1-max_plate_nesting`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model x.shape = torch.Size([3])\n",
      "model y.shape = torch.Size([3, 1])\n",
      "model z.shape = torch.Size([3, 1, 1])\n",
      "model x.shape = torch.Size([])\n",
      "model y.shape = torch.Size([])\n",
      "model z.shape = torch.Size([])\n",
      "x = 2\n",
      "y = 0\n",
      "z = 0\n"
     ]
    }
   ],
   "source": [
    "serving_model = infer_discrete(model, first_available_dim=-1)\n",
    "x, y, z = serving_model()   # The args is same args as model\n",
    "print(\"x = {}\".format(x))\n",
    "print(\"y = {}\".format(y))\n",
    "print(\"z = {}\".format(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，`infer_discrete`实际上运行了两次model（forward-filter mode and replay-backward-sample model）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing with enumerated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.shape = torch.Size([5, 4, 3, 2])\n",
      "x.shape = torch.Size([])\n",
      "y.shape = torch.Size([])\n",
      "p_xy.shape = torch.Size([5, 2])\n",
      "z.shape = torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "p = pyro.param(\"p\", torch.randn(5, 4, 3, 2).exp(), constraint=constraints.simplex)\n",
    "x = pyro.sample(\"x\", dist.Categorical(torch.ones(4)))\n",
    "y = pyro.sample(\"y\", dist.Categorical(torch.ones(3)))\n",
    "with pyro.plate(\"z_plate\", 5):\n",
    "    p_xy = p[..., x, y, :]\n",
    "    z = pyro.sample(\"z\", dist.Categorical(p_xy))\n",
    "    print(\"p.shape = {}\".format(p.shape))\n",
    "    print(\"x.shape = {}\".format(x.shape))\n",
    "    print(\"y.shape = {}\".format(y.shape))\n",
    "    print(\"p_xy.shape = {}\".format(p_xy.shape))\n",
    "    print(\"z.shape = {}\".format(z.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上方式运行成功，因为我们还没有使用enumeration mode。如果使用了enumeration mode，则x和y就不是一个scalar了，则其也不能用于index了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一种纯依靠pytorch来解决的办法是这样的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.shape = torch.Size([5, 4, 3, 2])\n",
      "x.shape = torch.Size([4, 1])\n",
      "y.shape = torch.Size([3, 1, 1])\n",
      "p_xy.shape = torch.Size([3, 4, 5, 2])\n",
      "z.shape = torch.Size([2, 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@config_enumerate\n",
    "def model():\n",
    "    p = pyro.param(\"p\", torch.randn(5, 4, 3, 2).exp(), constraint=constraints.simplex)\n",
    "    x = pyro.sample(\"x\", dist.Categorical(torch.ones(4)))\n",
    "    y = pyro.sample(\"y\", dist.Categorical(torch.ones(3)))\n",
    "    with pyro.plate(\"z_plate\", 5):\n",
    "        p_xy = p[\n",
    "            torch.arange(5, device=p.device).reshape(5, 1),     # 这里使用的是tensor的advanced indexing，这里所有维度的index会被broadcasting成相同的shape，\n",
    "            x.unsqueeze(-1),                                    # 然后结果的shape和此shape相同。\n",
    "            y.unsqueeze(-1),                                    # 比如：a[seq1, seq2, ...]，seq1和seq2等需要有相同的shape（或者可以被boardcasting成相同的shape），\n",
    "            torch.arange(2, device=p.device)                    # 然后，结果的shape和其相同，res[i1, i2, ...] = a[seq1[i1, i2, ...], seq2[i1, i2, ...], ...]\n",
    "        ]                                                       # 这里是将这4个tensor先broadcasting了：(5, 1), (4, 1, 1), (3, 1, 1, 1), (2)\n",
    "        z = pyro.sample(\"z\", dist.Categorical(p_xy))            #       5, 1\n",
    "    print(\"p.shape = {}\".format(p.shape))                       #    4, 1, 1\n",
    "    print(\"x.shape = {}\".format(x.shape))                       # 3 ,1, 1, 1\n",
    "    print(\"y.shape = {}\".format(y.shape))                       #          2\n",
    "    print(\"p_xy.shape = {}\".format(p_xy.shape))                 #          =\n",
    "    print(\"z.shape = {}\".format(z.shape))                       # 3, 4, 5, 2\n",
    "    return x, y, z\n",
    "\n",
    "def guide():\n",
    "    pass\n",
    "\n",
    "pyro.clear_param_store()\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "elbo.loss(model, guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是，pyro提供了一个工具`pyro.ops.indexing.Vindex`，使得我们可以使用non-enumeration的语法来对enumeration mode下的tensor进行index。其先对index进行类似的broadcasting。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.shape = torch.Size([5, 4, 3, 2])\n",
      "x.shape = torch.Size([])\n",
      "y.shape = torch.Size([])\n",
      "p_xy.shape = torch.Size([5, 2])\n",
      "z.shape = torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "p = pyro.param(\"p\", torch.randn(5, 4, 3, 2).exp(), constraint=constraints.simplex)\n",
    "x = pyro.sample(\"x\", dist.Categorical(torch.ones(4)))\n",
    "y = pyro.sample(\"y\", dist.Categorical(torch.ones(3)))\n",
    "with pyro.plate(\"z_plate\", 5):\n",
    "    p_xy = Vindex(p)[..., x, y, :]\n",
    "    z = pyro.sample(\"z\", dist.Categorical(p_xy))\n",
    "    print(\"p.shape = {}\".format(p.shape))\n",
    "    print(\"x.shape = {}\".format(x.shape))\n",
    "    print(\"y.shape = {}\".format(y.shape))\n",
    "    print(\"p_xy.shape = {}\".format(p_xy.shape))\n",
    "    print(\"z.shape = {}\".format(z.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.shape = torch.Size([5, 4, 3, 2])\n",
      "x.shape = torch.Size([4, 1])\n",
      "y.shape = torch.Size([3, 1, 1])\n",
      "p_xy.shape = torch.Size([3, 4, 5, 2])\n",
      "z.shape = torch.Size([2, 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@config_enumerate\n",
    "def model():\n",
    "    p = pyro.param(\"p\", torch.randn(5, 4, 3, 2).exp(), constraint=constraints.simplex)\n",
    "    x = pyro.sample(\"x\", dist.Categorical(torch.ones(4)))\n",
    "    y = pyro.sample(\"y\", dist.Categorical(torch.ones(3)))\n",
    "    with pyro.plate(\"z_plate\", 5):\n",
    "        p_xy = Vindex(p)[..., x, y, :]\n",
    "        z = pyro.sample(\"z\", dist.Categorical(p_xy))            \n",
    "    print(\"p.shape = {}\".format(p.shape))                       \n",
    "    print(\"x.shape = {}\".format(x.shape))                       \n",
    "    print(\"y.shape = {}\".format(y.shape))                       \n",
    "    print(\"p_xy.shape = {}\".format(p_xy.shape))                \n",
    "    print(\"z.shape = {}\".format(z.shape))                       \n",
    "    return x, y, z\n",
    "\n",
    "def guide():\n",
    "    pass\n",
    "\n",
    "pyro.clear_param_store()\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "elbo.loss(model, guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plates and enumeration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyro的enumeration strategy可以利用plates来reduce其cost。\n",
    "\n",
    "下面是一个例子，其构建了一个有着不同mean、相同variance的gaussian mixture model（具体的gmm模型的介绍，要到后面进行）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runing model with 10 data points\n",
      "x.shape = torch.Size([10])\n",
      "dist.Normal(loc[x], scale).batch_shape = torch.Size([10])\n",
      "Runing model with 10 data points\n",
      "x.shape = torch.Size([3, 1])\n",
      "dist.Normal(loc[x], scale).batch_shape = torch.Size([3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41.60341262817383"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@config_enumerate\n",
    "def model(data, num_components=3):\n",
    "    print(\"Runing model with {} data points\".format(len(data)))\n",
    "    p = pyro.sample(\"p\", dist.Dirichlet(0.5 * torch.ones(n_components)))   # beta分布的多维形式，用于每个数据点的components分布（categorical dist）的参数的先验\n",
    "    scale = pyro.sample(\"scale\", dist.LogNormal(0, num_components))        # 每个子gaussian dist的scale的分布\n",
    "    with pyro.plate(\"components\", num_components):                         # 每个子gaussian dist的mean是不同的，但其先验是相同的，都是N(0, 10)\n",
    "        loc = pyro.sample(\"loc\", dist.Normal(0, 10))\n",
    "    with pyro.plate(\"data\", len(data)):\n",
    "        x = pyro.sample(\"x\", dist.Categorical(p))                          # 每个样本属于哪个components，进行采样\n",
    "        print(\"x.shape = {}\".format(x.shape))\n",
    "        d = dist.Normal(loc[x], scale)                                     # 根据属于哪个components，进行gaussian采样\n",
    "        pyro.sample(\"obs\", d, obs=data)\n",
    "        print(\"dist.Normal(loc[x], scale).batch_shape = {}\".format(d.batch_shape))\n",
    "        \n",
    "guide = AutoDiagonalNormal(poutine.block(model, hide=[\"x\", \"data\"]))\n",
    "\n",
    "data = torch.randn(10)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "elbo.loss(model, guide, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看到，实际上每次这个model被运行了2次：\n",
    "\n",
    "1. 第一次是`AutoDiagonalNormal`运行的；\n",
    "2. 第二次是`elbo`去运行来计算loss，enumeration先为每一个data point都生成一个相同的3x1 tensor，然后使用broadcasting来实现快速计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies among plates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enumeration的计算节省是来自于dependency的restrictions，这些restrictions一般来说被`TraceEnum_ELBO`检查并添加到传统的independences中。这些可以被自动识别的restrictions一共有3种，如果违反了则会报错："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一种，在一个plate中的每个variable不能依赖于其他的任何一项。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二种，矢量化的plate外的变量不能依赖于其内的enumerated变量，比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config_enumerate\n",
    "def invalid_model(data):\n",
    "    with pyro.plate(\"plate\", 10):\n",
    "        x = pyro.sample(\"x\", dist.Bernoulli(0.5))\n",
    "    assert x.shape == (10,)\n",
    "    pyro.sample(\"obs\", dist.Normal(x.sum(), 1.), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果希望其成功，需要将矢量化的plate改成sequence的plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config_enumerate\n",
    "def valid_model(data):\n",
    "    x = []\n",
    "    for i in pyro.plate(\"plate\", 10):\n",
    "        x.append(pyro.sample(\"x_{}\".format(i), dist.Bernoulli(0.5)))\n",
    "    assert len(x) == 10\n",
    "    pyro.sample(\"obs\", dist.Normal(sum(x), 1.), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('learning': pyenv)",
   "language": "python",
   "name": "python37364bitlearningpyenv29fd259862cb48389e059aad46ca26e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
